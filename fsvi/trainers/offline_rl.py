import osfrom tqdm import tqdmimport timeimport csvimport pickleimport getpassfrom scipy.stats import normimport seqtoolsfrom functools import partialimport jaximport jax.numpy as jnpfrom jax import jit, grad, randomfrom jax.tree_util import tree_flattenimport haiku as hkimport optaximport numpy as npfrom sklearn.decomposition import PCAimport pandas as pdtry:    import joypyexcept:    passfrom gym.envs.mujoco import HalfCheetahEnv, HopperEnv, Walker2dEnv, AntEnvimport gymimport mj_envsimport random as random_pyimport datetimefrom scipy.stats import normfrom fsvi.utils.utils_training import Trainingfrom fsvi.utils.utils import get_minibatch, initialize_random_keysfrom fsvi.utils.haiku_mod import partition_paramsimport matplotlib.pyplot as pltimport seaborn as snssns.set()abspath = os.path.abspath(__file__)dname = os.path.dirname(abspath)path = dname + '/../..'# print(f'Setting working directory to {path}\n')os.chdir(path)from fsvi.utils import utilsfrom fsvi.utils import utils_loggingfrom fsvi.utils import utils_trainingfrom fsvi.models.networks import MLP as MLP, ACTIVATION_DICTdtype_default = jnp.float32# np.set_printoptions(suppress=True)eps = 1e-6name = 'door'env = gym.make('{}-binary-v0'.format(name))# from mjrl.utils.gym_env import GymEnv# env = GymEnv('door-binary-v0')def save_fn(ckpt_dir: str, name: str, state, kwargs) -> None:    with open(os.path.join(ckpt_dir, f"arrays_{name}.npy"), "wb") as f:        for x in jax.tree_leaves(state):            np.save(f, x, allow_pickle=False)    tree_struct = jax.tree_map(lambda t: 0, state)    with open(os.path.join(ckpt_dir, f"tree_{name}.pkl"), "wb") as f:        pickle.dump(tree_struct, f)    with open(os.path.join(ckpt_dir, f"kwargs_{name}.pkl"), "wb") as f:        pickle.dump(kwargs, f)def restore_fn(ckpt_dir, name: str, state):    tree_struct = jax.tree_map(lambda t: 0, state)    leaves, treedef = jax.tree_flatten(tree_struct)    with open(os.path.join(ckpt_dir, f"arrays_{name}.npy"), "rb") as f:        flat_state = [np.load(f) for _ in leaves]    kwargs_loaded = np.load(os.path.join(ckpt_dir, f"kwargs_{name}.pkl"), allow_pickle=True)    return jax.tree_unflatten(treedef, flat_state), kwargs_loadeddef rollout(env, model, max_path_length=np.inf, render=False, perturb_initial_state=False, pca=None):    """    The following value for the following keys will be a 2D array, with the    first dimension corresponding to the time dimension.     - observations     - actions     - rewards     - next_observations     - terminals    The next element will be a list of dictionaries, with the index into    the list being the index into the time     - env_infos    """    observations = []    observations_plot = []    actions = []    rewards = []    terminals = []    env_infos = []    o = env.reset()    next_o = None    path_length = 0    if perturb_initial_state:        for i in range(20):            o_input = np.array([o])            a = model(o_input)            a = a[0] if len(a) == 1 else a            if render:                # env.render()                env.env.mujoco_render_frames = True                env.env.mj_render()            next_o, r, d, env_info = env.step(a)    while path_length < max_path_length:        o_input = np.array([o])        a = model(o_input)        a = a[0] if len(a) == 1 else a        if render:            # env.render()            env.env.mujoco_render_frames = True            env.env.mj_render()        next_o, r, d, env_info = env.step(a)        if (path_length+1) % 20 == 0 and pca is not None and render:            pca_res = pca.transform(np.concatenate(observations_plot, 0))            fig = plt.figure(figsize=(6, 4.5))            ax = fig.add_subplot(111, title=f"")            plt.scatter(pca_res[:, 0], pca_res[:, 1])            outer_lim_plot = 5            ax.set_xlim(-outer_lim_plot, outer_lim_plot)            ax.set_ylim(-outer_lim_plot, outer_lim_plot)            plt.show()        observations.append(o)        observations_plot.append(o.reshape(1, -1))        rewards.append(r)        terminals.append(d)        actions.append(a)        env_infos.append(env_info)        path_length += 1        # if d:        #     break        o = next_o    actions = np.array(actions)    if len(actions.shape) == 1:        actions = np.expand_dims(actions, 1)    observations = np.array(observations)    if len(observations.shape) == 1:        observations = np.expand_dims(observations, 1)        next_o = np.array([next_o])    next_observations = np.vstack(        (            observations[1:, :],            np.expand_dims(next_o, 0)        )    )    return dict(        observations=observations,        actions=actions,        rewards=np.array(rewards).reshape(-1, 1),        next_observations=next_observations,        terminals=np.array(terminals).reshape(-1, 1),        env_infos=env_infos,    )def collect_new_paths(env, model, max_path_length, num_steps, discard_incomplete_paths, seed, render=False, perturb_initial_state=False, pca=None):    paths = []    num_steps_collected = 0    pbar = tqdm(total=num_steps)    env.env.seed(seed)    while num_steps_collected < num_steps:        max_path_length_this_loop = min(  # Do not go over num_steps            max_path_length,            num_steps - num_steps_collected,        )        path = rollout(env, model, max_path_length=max_path_length_this_loop, render=render, perturb_initial_state=perturb_initial_state, pca=pca)        eval_reward = np.sum(path['rewards'])        goal_state = True if eval_reward > -max_path_length else False        print(f"\nGoal achieved: {goal_state}")        path_len = len(path['actions'])        if (                path_len != max_path_length                and not path['terminals'][-1]                and discard_incomplete_paths        ):            break        num_steps_collected += path_len        paths.append(path)        pbar.update(path_len)    pbar.close()    return pathsdef plot_heatmap(    epoch,    model,    params,    state,    obs_pca,    rng_key,    n_samples_heatmap,    n_points,    outer_lim,    n_thresholds,    min_val_type,    max_val_type,    min_val,    max_val,    percentile,    traj_length_cum,    pca_xx,    pca_yy,    pca_res,):    _, _, preds_f_var_pca = model.predict_f_multisample(        params,        params,        state,        obs_pca,        rng_key,        n_samples_heatmap,        is_training=False    )    n = preds_f_var_pca.shape[0]    if max_val_type == 'var':        max_val = jnp.sort(preds_f_var_pca.mean(-1))[int(n * percentile)]    if min_val_type == 'var':        min_val = preds_f_var_pca.mean(-1).min()    preds_f_var_pca = np.reshape(preds_f_var_pca.mean(-1), [n_points, n_points])    if not isinstance(epoch, str):        epoch = epoch+1    fig = plt.figure(figsize=(6, 4.5))    ax = fig.add_subplot(111, title=f"Epoch: {epoch}")    outer_lim_plot = outer_lim    ax.set_xlim(-outer_lim_plot, outer_lim_plot)    ax.set_ylim(-outer_lim_plot, outer_lim_plot)    color = 'black'    contours = True    levels = np.linspace(min_val, max_val, n_thresholds)    # cpf = plt.contourf(pca_xx, pca_yy, preds_f_var_pca, cmap='coolwarm')    cpf = plt.contourf(pca_xx, pca_yy, preds_f_var_pca, levels=levels, cmap='coolwarm')    line_colors = ['black' for l in cpf.levels]    if contours:        # cp = ax.contour(pca_xx, pca_yy, preds_f_var_pca, colors=line_colors)        cp = ax.contour(pca_xx, pca_yy, preds_f_var_pca, levels=levels, colors=line_colors)    plt.colorbar()    for i in range(5):        plt.scatter(pca_res[traj_length_cum[i]:traj_length_cum[i+1], 0], pca_res[traj_length_cum[i]:traj_length_cum[i+1], 1], zorder=100, color=color)    plt.show()def offline_rl(    prior_mean: str,    prior_cov: str,    batch_size: int,    epochs: int,    seed: int,    save_path: str,    save: bool,    model_type: str,    **kwargs,):    kh = initialize_random_keys(seed=seed)    rng_key, rng_key_train, rng_key_test = random.split(kh.next_key(), 3)    np.random.seed(seed)    random_py.seed(seed)    # if getpass.getuser() == 'ANON':    #     path = '/scratch-ssd/ANON/deployment/testing/data/large/offpolicy_hand_data/'    # else:    #     path = '/Volumes/Data/Google_Drive/AYA_Google_Drive/Code/data/large/offpolicy_hand_data/'    #    # # data = np.load(path+'door-v0_demos.pickle', allow_pickle=True)    # # X = np.array([j for i in [traj['observations'] for traj in data] for j in i], dtype=dtype_default)    # # Y = np.array([j for i in [traj['actions'] for traj in data] for j in i], dtype=dtype_default)    #    # data = np.load('/scratch-ssd/ANON/deployment/testing/data/large/offpolicy_hand_data/door2_sparse.npy', allow_pickle=True)    # if type(data[0]['observations'][0]) is dict:    #     # Convert to just the states    #     for traj in data:    #         traj['observations'] = [t['state_observation'] for t in traj['observations']]    # X = np.array([j for i in [traj['observations'] for traj in data] for j in i], dtype=dtype_default)    # Y = np.array([j for i in [traj['actions'] for traj in data] for j in i], dtype=dtype_default)    #    # # data = np.load('/scratch-ssd/ANON/deployment/testing/data/large/offpolicy_hand_data/door-v0_demos.pickle', allow_pickle=True)    # # X = np.array([j for i in [traj['observations'][:150] for traj in data] for j in i])    # # Y = np.array([j for i in [traj['actions'][:150] for traj in data] for j in i])    if getpass.getuser() == 'ANON':        data = np.load("/scratch-ssd/ANON/deployment/testing/projects/nppac/expert_demonstration_data/door2_sparse.npy", allow_pickle=True)    else:        data = np.load("/Volumes/Data/Google_Drive/AYA_Google_Drive/Code/projects/nppac/expert_demonstration_data/door2_sparse.npy", allow_pickle=True)    random_split = False    if random_split:        keep_num = 1000        # Ablation to randomly filter the dataset, not active by default.        if keep_num < len(data):            print(f'Keeping {keep_num} trajectories.')            data = np.random.choice(data, keep_num, replace=False)            with open(f'nppac/{save_dir}/data.npy', 'wb') as f:                np.save(f, data)        if type(data[0]['observations'][0]) is dict:            # Convert to just the states            for traj in data:                traj['observations'] = [t['state_observation'] for t in traj['observations']]        X = jnp.array([j for i in [traj['observations'] for traj in data] for j in i])        Y = jnp.array([j for i in [traj['actions'] for traj in data] for j in i])        train_test_split_ratio = 0.8        n = X.shape[0]        n_train = int(n * train_test_split_ratio)        # n_test = n - n_train        idx = np.random.permutation(n)        idx_train = idx[0:n_train]        idx_test = idx[n_train:]        x_train = X[idx_train]        x_test = X[idx_test]        y_train = Y[idx_train]        y_test = Y[idx_test]    else:        num_traj_test = 2        num_traj_all = len(data)        num_traj_train = num_traj_all - num_traj_test        assert num_traj_test < num_traj_all        data_train = data[:num_traj_train]        data_test = data[-num_traj_test:]        if type(data[0]['observations'][0]) is dict:            traj_length_list = []            traj_length_cum = []            i = 0            # Convert to just the states            for traj in data_train:                traj['observations'] = [t['state_observation'] for t in traj['observations']]                traj_length_list.append(len(traj['observations']))                traj_length_cum.append(int(np.sum(traj_length_list[0:i])))                i+=1            for traj in data_test:                traj['observations'] = [t['state_observation'] for t in traj['observations']]        x_train = jnp.array([j for i in [traj['observations'] for traj in data_train] for j in i])        y_train = jnp.array([j for i in [traj['actions'] for traj in data_train] for j in i])        x_test = jnp.array([j for i in [traj['observations'] for traj in data_test] for j in i])        y_test = jnp.array([j for i in [traj['actions'] for traj in data_test] for j in i])    n_train = x_train.shape[0]    if batch_size == 0:        batch_size = n_train        n_batches = n_train // batch_size    else:        n_batches = n_train // batch_size + 1    # kwargs['noise_std'] = noise_std = 1 #0.001    # noise_std = 1.0    noise_var = kwargs['noise_std']  ** 2    kwargs['tau'] = tau = 1 / noise_var    input_dim = 39  #x_train.shape[1]    input_shape = [6255, 39]  #list(x_train.shape)    output_dim = 28  #y_train.shape[1]    if getpass.getuser() == 'ANON':        render = False    elif getpass.getuser() == 'ANON':        render = True    else:        render = False    n_points = 80    n_samples_heatmap = 50    outer_lim = 10    outer_lim_plot = 4    n_thresholds = 10    min_val_type = 'var'    max_val_type = 'var'    min_val = 0    max_val = 0.05    percentile = 0.1    freq_eval = kwargs["logging_frequency"]    freq_eval_online = 2000    max_path_length = 300    n_test_episodes = 5    num_eval_points = 20    ids = np.random.choice(y_train.shape[1], num_eval_points, replace=False)    # ids = range(num_eval_points)    ids_train = ids    ids_test = ids    # ids_train = ids[np.argsort(y_train[ids][:,0])]    # ids_test = ids[np.argsort(y_test[ids][:,0])]    # DEFINE NUMPY TRAINLOADER  # TODO: test implementation    n_train = x_train.shape[0]    # load trainloader directly instead than constructing it from scratch    if batch_size == n_train:        trainloader = [[x_train, y_train]]    else:        try:            if getpass.getuser() == 'ANON':                trainloader = np.load(f"/scratch-ssd/ANON/deployment/testing/projects/nppac/expert_demonstration_data/door2_sparse_trainloader_{batch_size}.npy", allow_pickle=True)        except:            train_dataset = seqtools.collate([x_train, y_train])            if batch_size == 0:                trainloader = seqtools.batch(train_dataset, n_train, collate_fn=utils.collate_fn)            else:                trainloader = seqtools.batch(train_dataset, batch_size, collate_fn=utils.collate_fn)            _trainloader = []            for i, minibatch in enumerate(trainloader, 0):                x_batch = jnp.array(minibatch[0], dtype=dtype_default)                y_batch = jnp.array(minibatch[1], dtype=dtype_default)                _trainloader.append([x_batch, y_batch])            trainloader = _trainloader            with open(f"/scratch-ssd/ANON/deployment/testing/projects/nppac/expert_demonstration_data/door2_sparse_trainloader_{batch_size}.npy", "wb") as file:                pickle.dump(trainloader, file)    generate_random_rollouts = True    if generate_random_rollouts and render == False:        try:            ps_random = np.load(f"/scratch-ssd/ANON/deployment/testing/projects/nppac/expert_demonstration_data/door2_sparse_random_rollouts_seed_{seed}.npy", allow_pickle=True)        except:            random_policy = lambda state: np.random.normal(loc=0., scale=1., size=[1, output_dim])            max_path_length_random = 300            n_test_episodes_random = 100            ps_random = collect_new_paths(                env,                random_policy,                max_path_length_random,                max_path_length_random * n_test_episodes_random,                discard_incomplete_paths=False,                seed=seed+1,                render=render,                perturb_initial_state=True,            )        _x_inducing = jnp.array([j for i in [traj['observations'] for traj in ps_random] for j in i])        _y_inducing = jnp.array([j for i in [traj['actions'] for traj in ps_random] for j in i])        idx = np.random.permutation(_x_inducing.shape[0])        x_inducing = _x_inducing[idx]        y_inducing = _y_inducing[idx]        with open(f"/scratch-ssd/ANON/deployment/testing/projects/nppac/expert_demonstration_data/door2_sparse_random_rollouts_seed_{seed}.npy", "wb") as file:            pickle.dump(ps_random, file)        ## plot random rollouts:        # pca = PCA(n_components=2)        # pca.fit(x_train)        # pca_res_inducing = pca.transform(_x_inducing)        # traj_random_length_cum = [i * max_path_length_random for i in range(n_test_episodes_random)]        # for i in range(90):        #     plt.scatter(pca_res_inducing[traj_random_length_cum[i]:traj_random_length_cum[i+1], 0], pca_res_inducing[traj_random_length_cum[i]:traj_random_length_cum[i+1], 1])        #     plt.xlim(-outer_lim, outer_lim)        #     plt.ylim(-outer_lim, outer_lim)        # plt.show()    pca = PCA(n_components=2)    pca.fit(x_train)    pca_res = pca.transform(x_train)    ## plot expert trajectories:    # for i in range(len(data_train)-1):    #     plt.scatter(pca_res[traj_length_cum[i]:traj_length_cum[i+1], 0], pca_res[traj_length_cum[i]:traj_length_cum[i+1], 1])    # plt.show()    pca_grid_points = np.linspace(-outer_lim, outer_lim, n_points)    pca_xx, pca_yy = np.meshgrid(pca_grid_points, pca_grid_points, indexing='ij')    pca_xx_flat = np.reshape(pca_xx, (n_points * n_points, 1))    pca_yy_flat = np.reshape(pca_yy, (n_points * n_points, 1))    pca_coords = np.concatenate([pca_xx_flat, pca_yy_flat], axis=1)    obs_pca = pca.inverse_transform(pca_coords)    ### OOD inducing inputs    pca_grid_points = np.linspace(kwargs["inducing_inputs_bound"][0], kwargs["inducing_inputs_bound"][1], n_points)    pca_xx, pca_yy = np.meshgrid(pca_grid_points, pca_grid_points, indexing='ij')    pca_xx_flat = np.reshape(pca_xx, (n_points * n_points, 1))    pca_yy_flat = np.reshape(pca_yy, (n_points * n_points, 1))    pca_coords = np.concatenate([pca_xx_flat, pca_yy_flat], axis=1)    _x_inducing = pca_coords    # _x_inducing = pca_coords[np.linalg.norm(_x_inducing, axis=1) > 4]    x_inducing = pca.inverse_transform(_x_inducing)    val_frac = 0.0    x_train_permuted = x_train    y_train_permuted = y_train    if generate_random_rollouts and render == False:        x_ood = x_inducing        y_ood = y_inducing    else:        x_ood = x_train        y_ood = y_train    # INITIALIZE TRAINING CLASS    training = Training(        input_shape=input_shape,        output_dim=output_dim,        n_train=n_train,        epochs=epochs,        batch_size=batch_size,        n_batches=n_train // batch_size,        # TODO: unify the run.py for classification ood        full_ntk=kwargs["full_cov"],        model_type=model_type,        **kwargs,    )    # INITIALIZE MODEL    (model, init_fn, apply_fn, state, params) = training.initialize_model(        rng_key=rng_key, x_train=x_train_permuted, x_ood=[x_train],    )    # INITIALIZE OPTIMIZATION    (        opt,        opt_state,        get_trainable_params,        get_variational_and_model_params,        metrics,        loss,        kl_evaluation,        log_likelihood_evaluation,        nll_grad_evaluation,        task_evaluation,        prediction_type,    ) = training.initialize_optimization(        model=model,        apply_fn=apply_fn,        params_init=params,        state=state,        rng_key=rng_key,    )    # INITIALIZE KL INPUT FUNCTIONS    inducing_input_fn, prior_fn = training.kl_input_functions(        apply_fn=apply_fn,        predict_f=model.predict_f,        predict_f_deterministic=model.predict_f_deterministic,        state=state,        params=params,        prior_mean=prior_mean,        prior_cov=prior_cov,        rng_key=rng_key,        x_ood=[x_ood],        y_ood=[y_ood],    )    # INITIALIZE LOGGING CLASS    epoch_start = 0    logging = utils_logging.Logging(        model=model,        apply_fn=apply_fn,        metrics=metrics,        loss=loss,        kl_evaluation=kl_evaluation,        log_likelihood_evaluation=log_likelihood_evaluation,        nll_grad_evaluation=nll_grad_evaluation,        task_evaluation=task_evaluation,        epoch_start=epoch_start,        x_train_permuted=x_train_permuted,        y_train_permuted=y_train_permuted,        x_test=x_test,        y_test=y_test,        x_ood=[x_ood],        n_train=n_train,        val_frac=val_frac,        epochs=epochs,        save=save,        save_path=save_path,        model_type=model_type,        **kwargs,    )    @jit    def update(        params,        params_feature,        state,        opt_state_mu,        opt_state_var,        x_batch,        y_batch,        inducing_inputs,        rng_key,        prior_cov,    ):        trainable_params, non_trainable_params = get_trainable_params(params)        variational_params, model_params = get_variational_and_model_params(params)        _prior_mean, _prior_cov = prior_fn(            inducing_inputs=inducing_inputs,            model_params=model_params,            rng_key=rng_key,            prior_cov=prior_cov,            state=state,        )        grads, new_state = jax.grad(loss, argnums=0, has_aux=True)(            trainable_params,            [non_trainable_params,params_feature],            state,            _prior_mean,            _prior_cov,            x_batch,            y_batch,            inducing_inputs,            rng_key,        )        zero_grads = jax.tree_map(lambda x: x * 0., non_trainable_params)        grads = jax.tree_map(lambda x: x * 1., grads)        grads_full = hk.data_structures.merge(grads, zero_grads)        if opt_var is None:            updates, opt_state_mu = opt_mu.update(grads_full, opt_state_mu)            new_params = optax.apply_updates(params, updates)        else:            grads_full_mu, grads_full_var, _ = partition_params(grads_full)            updates_mu, opt_mu_state = opt_mu.update(grads_full_mu, opt_state_mu)            updates_var, opt_var_state = opt_var.update(grads_full_var, opt_state_var)            updates = hk.data_structures.merge(updates_mu, updates_var)            new_params = optax.apply_updates(params, updates)        is_nan = jnp.isnan(jax.flatten_util.ravel_pytree(new_params)[0]).any()        nan_check = [is_nan, params, new_params, grads_full]        params = new_params        return params, opt_state_mu, opt_state_var, new_state, nan_check    if not isinstance(opt, list):        opt_mu, opt_var = opt, None        opt_state_mu, opt_state_var = opt_state, None    else:        opt_mu, opt_var = opt        opt_state_mu, opt_state_var = opt_state    if kwargs["evaluate"]:        max_path_length_eval = 300        n_test_episodes_eval = 30        ckpt_dir = "saved_models/offline_rl/thesis/active/"        architecture_id = kwargs["architecture_arg"]        inducing_input_type = kwargs["inducing_input_type"]        # name = f"{architecture_id}_001"        ### choose config        name = f"{architecture_id}_{model_type}_{prior_cov}_{inducing_input_type}_lin_001_gf"        params, kwargs_loaded = restore_fn(ckpt_dir, name, params)        epoch = name        print(f"Loaded {name}")        pred_fn_partial = partial(model._predict_f_deterministic, params=params, params_feature=params, state=state, rng_key=rng_key, is_training=False)        pred_fn_jit = jax.jit(pred_fn_partial)        pred_fn = lambda x: pred_fn_jit(inputs=x)        pred_sample_fn_partial = partial(model.predict_f_multisample, params=params, params_feature=params, state=state, rng_key=rng_key, is_training=False)        # pred_sample_fn_jit = jax.jit(pred_sample_fn_partial)        pred_sample_fn = lambda x, n_samples: pred_sample_fn_partial(inputs=x, n_samples=n_samples)        if kwargs["data_training"] == "online_rl":            return ((pred_fn, pred_sample_fn), trainloader)        # if getpass.getuser() == 'ANON':        #     plot_heatmap(        #         epoch, model, params, state, obs_pca, rng_key, n_samples_heatmap,        #         n_points, outer_lim_plot, n_thresholds, min_val_type, max_val_type, min_val, max_val,        #         percentile, traj_length_cum, pca_xx, pca_yy, pca_res,        #     )        print(f"Starting online evaluation with max_path_length={max_path_length_eval} and n_test_episodes={n_test_episodes_eval}")        start = datetime.datetime.now()        ps = collect_new_paths(            env,            pred_fn,            max_path_length_eval,            max_path_length_eval * n_test_episodes_eval,            discard_incomplete_paths=True,            seed=seed,            render=render,            # pca=pca,        )        finish = datetime.datetime.now()        time_eval = finish - start        print(f"Profiling took: {time_eval}")        eval_rew = np.mean([np.sum(p['rewards']) for p in ps])        eval_std = np.std([np.sum(p['rewards']) for p in ps])        print(f"Eval Reward: {eval_rew:.2f}  |  Std: {eval_std:.2f}")        rews = [np.sum(p['rewards']) for p in ps]        blist = [1 if k > -max(max_path_length_eval,200) else 0 for k in rews]        perc = int(dtype_default(sum(blist)) / dtype_default(len(blist)) * 100)        print(f"Success Rate: {perc:.2f}%")        print(f"Evaluation complete.")    print(f"\n--- Training for {epochs} epochs ---\n")    for epoch in range(epochs):        if epoch % freq_eval == 0:            t0 = time.time()        for i, data in enumerate(trainloader, 0):            if logging.feature_update or (i+1) % kwargs["feature_update"] == 0 or epoch < 0:                params_feature = params                logging.feature_update = False            rng_key_train, _ = random.split(rng_key_train)            x_batch, y_batch = get_minibatch(data, output_dim, input_shape, prediction_type)            inducing_inputs = inducing_input_fn(x_batch, rng_key_train)            if kwargs["inducing_input_type"] == "ood_rand" and kwargs["full_cov"] and "tdvi" in model_type:                permutation = jax.random.permutation(key=rng_key_train, x=x_batch.shape[0])                x_batch_subset = x_batch[permutation][:kwargs["n_inducing_inputs"]]                inducing_inputs = jnp.concatenate([inducing_inputs, x_batch_subset], axis=0)            params, opt_state_mu, opt_state_var, state, nan_check = update(                params,                params_feature,                state,                opt_state_mu,                opt_state_var,                x_batch,                y_batch,                inducing_inputs,                rng_key_train,                dtype_default(prior_cov),            )            assert not nan_check[0]            pred_fn_partial = partial(model._predict_f_deterministic, params=params, params_feature=params, state=state, rng_key=rng_key, is_training=False)            pred_fn_jit = jax.jit(pred_fn_partial)            pred_fn = lambda x: pred_fn_jit(inputs=x)        if (epoch + 1) % freq_eval == 0:            y_train_pred = pred_fn(x_train)            sq_train = (y_train - y_train_pred) ** 2            rmse_train = np.mean(sq_train ** 2) ** 0.5            y_test_pred = pred_fn(x_test)            sq_test = (y_test - y_test_pred) ** 2            rmse_test = np.mean(sq_test) ** 0.5            T = time.time()            time_ep = (T - t0) / freq_eval            print(f"Epoch: {epoch + 1}  |  RMSE (train): {rmse_train:0.5f}  |  RMSE (test): {rmse_test:0.3f}  |  Time (epoch): {time_ep:3.2f}s")        if (epoch + 1) % (freq_eval * 50) == 0:# or epoch == 0:            plot_heatmap(                epoch, model, params, state, obs_pca, rng_key, n_samples_heatmap,                n_points, outer_lim_plot, n_thresholds, min_val_type, max_val_type, min_val, max_val,                percentile, traj_length_cum, pca_xx, pca_yy, pca_res,            )        if (epoch + 1) % (freq_eval * 50) == 0:            print(f"Starting online evaluation with max_path_length={max_path_length} and n_test_episodes={n_test_episodes}")            start = datetime.datetime.now()            ps = collect_new_paths(                env,                pred_fn,                max_path_length,                max_path_length * n_test_episodes,                seed=seed,                discard_incomplete_paths=True,                render=render,            )            finish = datetime.datetime.now()            time_eval = finish - start            print(f"Profiling took: {time_eval}")            eval_rew = np.mean([np.sum(p['rewards']) for p in ps])            eval_std = np.std([np.sum(p['rewards']) for p in ps])            print(f"Epoch {epoch+1:3.0f} |  Eval Reward: {eval_rew}  |  Std: {eval_std}")            rews = [np.sum(p['rewards']) for p in ps]            blist = [1 if k > -max(max_path_length,200) else 0 for k in rews]            perc = int(dtype_default(sum(blist)) / dtype_default(len(blist)) * 100)            print(f"Success Rate: {perc:.2f}%")    if save:        ckpt_dir = "saved_models/offline_rl/thesis/active/"        architecture_id = kwargs["architecture_arg"]        inducing_input_type = kwargs["inducing_input_type"]        # name = f"{architecture_id}_001"        name = f"{architecture_id}_{model_type}_{prior_cov}_{inducing_input_type}_lin_001_gf"        save_fn(ckpt_dir, name, params, kwargs)        # with open(f"{ckpt_dir}params.npy", "wb") as file:        #     pickle.dump(params, file, protocol=4)